{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# \ud83e\udde0 Legal-BERT Trainer with LEDGAR Dataset\n",
        "This notebook uses Hugging Face's `Trainer` API to fine-tune Legal-BERT on the LEDGAR contract clause classification task."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "!pip install transformers datasets huggingface_hub accelerate"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from huggingface_hub import login\n",
        "login(token=\"hf_your_token_here\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Load LEDGAR dataset and model\n",
        "from datasets import load_dataset\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
        "\n",
        "dataset = load_dataset(\"lex_glue\", \"ledgar\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"nlpaueb/legal-bert-base-uncased\")\n",
        "\n",
        "def tokenize(example):\n",
        "    return tokenizer(example['text'], padding=\"max_length\", truncation=True)\n",
        "\n",
        "encoded_dataset = dataset.map(tokenize, batched=True)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"nlpaueb/legal-bert-base-uncased\", num_labels=100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Setup Trainer API\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    num_train_epochs=1,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir=\"./logs\",\n",
        "    logging_steps=10,\n",
        "    save_strategy=\"epoch\"\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=encoded_dataset[\"train\"],\n",
        "    eval_dataset=encoded_dataset[\"validation\"]\n",
        ")\n",
        "\n",
        "trainer.train()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "**Generated and managed by BitstandBytes | Legal NLP Automation Pipeline**\n",
        "- Author: Shaun Muldowney\n",
        "- Dataset: LEDGAR (LexGLUE)\n",
        "- Trainer: Hugging Face `Trainer` with Legal-BERT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# \ud83e\udde0 Load classification training dataset\n",
        "!pip install datasets\n",
        "from datasets import load_dataset\n",
        "dataset = load_dataset('json', data_files='legalbert_training_dataset.jsonl', split='train')\n",
        "\n",
        "# Preview dataset\n",
        "print(dataset[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# \ud83e\udde0 Load NER tagging dataset\n",
        "ner_dataset = load_dataset('json', data_files='legalbert_ner_dataset.jsonl', split='train')\n",
        "\n",
        "# Check NER example\n",
        "print(ner_dataset[0])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}